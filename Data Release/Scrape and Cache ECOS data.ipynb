{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FWS Ecological Conservation Online System contains information about T&E species along with other information. USGS EMA staff (or others?) went through the work plan species list, determined the appropriate links to ECOS species web pages, and recorded those in one of the tables provided in the source inventory. In reviewing the various systems and access points, we found that there is information on ECOS species web pages that is not accessible through the ECOS TESS web services. We also found that the identifiers used on the ECOS species web pages do not seem to be found anywhere in the other accessible TESS interfaces. From this, we determined that we should run a rudimentary web scraping tool to gather a few usable pieces of information from the linked ECOS pages as a first step, cache this information in a file, and use it in later work.\n",
    "\n",
    "One of the main things extracted here is FWS' own determination of the appropriate ITIS species to link to. We use this in favor of running a species search whenever it's available as one avenue of establishing a linkage and retrieving information for later use.\n",
    "\n",
    "In writing the ECOS web scraper, we found that the ECOS pages are really quite hard to deal with. They are assembled dynamically from what appear to be various sources in a somewhat inconsistent way in terms of where and how the information is output to HTML/Javascript on the pages. This first scraper is kind of crude, and we'll revisit as needed down the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep\n",
    "The ECOS links were contained in the \"FWS 7 Year Workplan Species\" worksheet from the original \"Prelisting Science USGS Master_19Mar2018\" spreadsheet used as source material for this exercise. The links were embedded as hyperlinks on the species \"Scientific Name\" field using Excel proprietary methods. As such, we had to use a simple VBA script to extract out the links to their own field. We did this by copying the scientific name fields over to another Excel file, running the VBA macro there, and then including that as an intermediary file for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bispy\n",
    "from IPython.display import display\n",
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "import random\n",
    "\n",
    "ecos = bispy.tess.Ecos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the extraction of ECOS links with scientific names from an excel file\n",
    "spp_ecos_links = pd.read_excel(\n",
    "    \"sources/AssitionalSourceData.xlsx\",\n",
    "    sheet_name=\"Extracted Species ECOS Links\"\n",
    ")\n",
    "# Put just the links into a list for processing\n",
    "ecos_link_list = spp_ecos_links[spp_ecos_links[\"ECOS Link\"].notnull()][\"ECOS Link\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use joblib to run multiple requests for ECOS documents in parallel\n",
    "ecos_cache = Parallel(n_jobs=8)(delayed(ecos.scrape_ecos)(url) for url in ecos_link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the cache of ecos data to a JSON file for later use\n",
    "with open(\"cache/ecos.json\", 'w') as f:\n",
    "    f.write(json.dumps(ecos_cache, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Common Name': 'Yellow banded Bumble bee',\n",
       " 'Federal Register Documents': [{'Citation Page': '81 FR 14058 14072',\n",
       "   'Date': '2016-03-16',\n",
       "   'Title': '90-Day Findings on 29 Petitions; Notice of petition findings and initiation of status reviews',\n",
       "   'Title_link': 'https://www.govinfo.gov/link/fr/81/14058?link-type=pdf'}],\n",
       " 'ITIS TSN': '714843',\n",
       " 'Processing Metadata': {'Date Processed': '2019-07-01T16:47:35.650051',\n",
       "  'Search URL': 'https://ecos.fws.gov/ecp/species/10403',\n",
       "  'Status': 'Page Successfully Retrieved'},\n",
       " 'Scientific Name': 'Bombus terricola',\n",
       " 'Status Summary': [{'Date Listed': '',\n",
       "   'Lead Region': 'Northeast Region (Region 5)',\n",
       "   'Lead Region_link': 'http://www.fws.gov/northeast/',\n",
       "   'Status': 'Under Review',\n",
       "   'Where Listed': 'Wherever found'}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Open up the JSON file and validate that it works showing number of cached records and an example\n",
    "with open(\"cache/ecos.json\", \"r\") as f:\n",
    "    cached_ecos_data = json.loads(f.read())\n",
    "\n",
    "print(len(cached_ecos_data))\n",
    "display(cached_ecos_data[random.randint(0,len(cached_ecos_data)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
